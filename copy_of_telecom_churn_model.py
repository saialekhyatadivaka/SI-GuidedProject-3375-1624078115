# -*- coding: utf-8 -*-
"""Copy of telecom churn model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SuY8KGB1iiwbmo5lpKWDwVskZ3wtexb0
"""

#import necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

#import dataset
data = pd.read_csv(r"C:\Users\ACER\Desktop\data science\Telecom churn modelling\data\DataSet.csv")

data.head()

data.drop(["customerID"], axis =1, inplace = True)

data.head()

data.describe()

data.info()

#checking for null values
data.TotalCharges = pd.to_numeric(data.TotalCharges, errors='coerce')
data.isnull().any()

data.isnull().sum()

=True)

data.isnull().sum()

data.corr()

sns.heatmap(data.corr(), annot=True)

sns.pairplot(data=data, markers=["^","v"], palette="inferno")

for i in data:
    print(data[i].unique())

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
data["gender"] = le.fit_transform(data["gender"])
data["Partner"] = le.fit_transform(data["Partner"])
data["Dependents"] = le.fit_transform(data["Dependents"])
data["PhoneService"] = le.fit_transform(data["PhoneService"])
data["MultipleLines"] = le.fit_transform(data["MultipleLines"])
data["InternetService"] = le.fit_transform(data["InternetService"])
data["OnlineSecurity"] = le.fit_transform(data["OnlineSecurity"])
data["OnlineBackup"] = le.fit_transform(data["OnlineBackup"])
data["DeviceProtection"] = le.fit_transform(data["DeviceProtection"])
data["TechSupport"] = le.fit_transform(data["TechSupport"])
data["StreamingTV"] = le.fit_transform(data["StreamingTV"])
data["StreamingMovies"] = le.fit_transform(data["StreamingMovies"])
data["Contract"] = le.fit_transform(data["Contract"])
data["PaperlessBilling"] = le.fit_transform(data["PaperlessBilling"])
data["PaymentMethod"] = le.fit_transform(data["PaymentMethod"])
data["Churn"] = le.fit_transform(data["Churn"])

data.head()

data.info()

data.corr()

sns.heatmap(data.corr(), annot=False)

sns.pairplot(data=data, markers=["^","v"], palette="inferno")

x= data.iloc[:,0:19].values
y= data.iloc[:,19:20].values

x

y

x.shape

y.shape

from sklearn.preprocessing import OneHotEncoder
one = OneHotEncoder()
a= one.fit_transform(x[:,6:7]).toarray()
b= one.fit_transform(x[:,7:8]).toarray()
c= one.fit_transform(x[:,8:9]).toarray()
d= one.fit_transform(x[:,9:10]).toarray()
e= one.fit_transform(x[:,10:11]).toarray()
f= one.fit_transform(x[:,11:12]).toarray()
g= one.fit_transform(x[:,12:13]).toarray()
h= one.fit_transform(x[:,13:14]).toarray()
i= one.fit_transform(x[:,14:15]).toarray()
j= one.fit_transform(x[:,16:17]).toarray()
x=np.delete(x,[6,7,8,9,10,11,12,13,14,16],axis=1)
x=np.concatenate((a,b,c,d,e,f,g,h,i,j,x),axis=1)

x.shape

y.shape

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2, random_state = 0)

x_train

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.fit_transform(x_test)

from sklearn.linear_model import LogisticRegression
lr = LogisticRegression(random_state=0)
lr.fit(x_train,y_train)

lr_pred = lr.predict(x_test)

lr_pred

y_test

from sklearn.metrics import accuracy_score
lr_acc = accuracy_score(lr_pred,y_test)

lr_acc

from sklearn.metrics import confusion_matrix
lr_cm = confusion_matrix(lr_pred,y_test)

lr_cm

from sklearn.tree import DecisionTreeClassifier
dtc = DecisionTreeClassifier(random_state = 0,criterion = "entropy")
dtc.fit(x_train,y_train)

dtc_pred = dtc.predict(x_test)

dtc_pred

dtc_acc = accuracy_score(dtc_pred,y_test)

dtc_acc

dtc_cm = confusion_matrix(dtc_pred,y_test)

dtc_cm

from sklearn.ensemble import RandomForestClassifier
rfc= RandomForestClassifier(n_estimators = 10, criterion = "entropy",random_state=0)
rfc.fit(x_train,y_train)

rfc_pred = rfc.predict(x_test)

rfc_pred

rfc_acc = accuracy_score(rfc_pred,y_test)

rfc_acc

rfc_cm = confusion_matrix(rfc_pred,y_test)

rfc_cm

from sklearn.svm import SVC
svm = SVC(kernel = "linear")
svm.fit(x_train,y_train)

svm_pred = svm.predict(x_test)

svm_pred

svm_acc = accuracy_score(svm_pred,y_test)

svm_acc

svm_cm = confusion_matrix(svm_pred,y_test)

svm_cm

svm_pred_own = svm.predict(sc.transform([[0,0,1,1,0,0,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,1,0,0,1,1,0,0,456,1,0,3245,4567]]))

svm_pred_own

import pickle
pickle.dump(svm,open("churn.pkl" , "wb"))

